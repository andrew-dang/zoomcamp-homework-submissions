2024-04-14T16:33:47 {"block_run_id": 9, "block_uuid": "load_daily_schedule", "pipeline_run_id": 4, "pipeline_schedule_id": 4, "pipeline_uuid": "seed_bq", "hostname": "78c121f5c730", "block_type": "data_loader", "level": "INFO", "message": "Start executing block with BlockExecutor.", "timestamp": 1713112427.315682, "uuid": "d126ea853198422886b630b0bdea33e4"}
2024-04-14T16:33:54 {"block_run_id": 9, "block_uuid": "load_daily_schedule", "pipeline_run_id": 4, "pipeline_schedule_id": 4, "pipeline_uuid": "seed_bq", "hostname": "78c121f5c730", "block_type": "data_loader", "level": "WARNING", "message": "Exception thrown when attempting to run <function BlockExecutor.execute.<locals>.__execute_with_retry at 0x7f861d9d5480>, attempt 1 of 1", "timestamp": 1713112434.459039, "uuid": "2f7ae76f90cc4b85ae5e4c4edde148aa", "error": ["Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/google/cloud/bigquery/dbapi/cursor.py\", line 213, in _execute\n    self._query_job.result()\n  File \"/usr/local/lib/python3.10/site-packages/google/cloud/bigquery/job/query.py\", line 1595, in result\n    do_get_result()\n  File \"/usr/local/lib/python3.10/site-packages/google/api_core/retry.py\", line 372, in retry_wrapped_func\n    return retry_target(\n  File \"/usr/local/lib/python3.10/site-packages/google/api_core/retry.py\", line 207, in retry_target\n    result = target()\n  File \"/usr/local/lib/python3.10/site-packages/google/cloud/bigquery/job/query.py\", line 1584, in do_get_result\n    super(QueryJob, self).result(retry=retry, timeout=timeout)\n  File \"/usr/local/lib/python3.10/site-packages/google/cloud/bigquery/job/base.py\", line 952, in result\n    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/google/api_core/future/polling.py\", line 261, in result\n    raise self._exception\ngoogle.api_core.exceptions.BadRequest: 400 Already Exists: Table leafy-valor-420311:nba_api._dlt_version at [9:1]\n\nLocation: US\nJob ID: 3c3e8a51-33cf-4054-aafa-1837d9dc82f4\n\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/dlt/destinations/sql_client.py\", line 243, in _wrap_gen\n    return (yield from f(self, *args, **kwargs))\n  File \"/usr/local/lib/python3.10/site-packages/dlt/destinations/impl/bigquery/sql_client.py\", line 215, in execute_query\n    curr.execute(query, db_args, job_config=self._session_query or self._default_query)\n  File \"/usr/local/lib/python3.10/site-packages/google/cloud/bigquery/dbapi/_helpers.py\", line 494, in with_closed_check\n    return method(self, *args, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/google/cloud/bigquery/dbapi/cursor.py\", line 176, in execute\n    self._execute(\n  File \"/usr/local/lib/python3.10/site-packages/google/cloud/bigquery/dbapi/cursor.py\", line 215, in _execute\n    raise exceptions.DatabaseError(exc)\ngoogle.cloud.bigquery.dbapi.exceptions.DatabaseError: 400 Already Exists: Table leafy-valor-420311:nba_api._dlt_version at [9:1]\n\nLocation: US\nJob ID: 3c3e8a51-33cf-4054-aafa-1837d9dc82f4\n\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/dlt/pipeline/pipeline.py\", line 503, in load\n    runner.run_pool(load_step.config, load_step)\n  File \"/usr/local/lib/python3.10/site-packages/dlt/common/runners/pool_runner.py\", line 88, in run_pool\n    while _run_func():\n  File \"/usr/local/lib/python3.10/site-packages/dlt/common/runners/pool_runner.py\", line 81, in _run_func\n    run_metrics = run_f.run(cast(TExecutor, pool))\n  File \"/usr/local/lib/python3.10/site-packages/dlt/load/load.py\", line 564, in run\n    self.load_single_package(load_id, schema)\n  File \"/usr/local/lib/python3.10/site-packages/dlt/load/load.py\", line 448, in load_single_package\n    applied_update = self._init_client(\n  File \"/usr/local/lib/python3.10/site-packages/dlt/load/load.py\", line 423, in _init_client\n    applied_update = self._init_dataset_and_update_schema(\n  File \"/usr/local/lib/python3.10/site-packages/dlt/load/load.py\", line 398, in _init_dataset_and_update_schema\n    applied_update = job_client.update_stored_schema(\n  File \"/usr/local/lib/python3.10/site-packages/dlt/destinations/job_client_impl.py\", line 200, in update_stored_schema\n    applied_update = self._execute_schema_update_sql(only_tables)\n  File \"/usr/local/lib/python3.10/site-packages/dlt/destinations/job_client_impl.py\", line 399, in _execute_schema_update_sql\n    self.sql_client.execute_many(sql_scripts)\n  File \"/usr/local/lib/python3.10/site-packages/dlt/destinations/sql_client.py\", line 133, in execute_many\n    ret.append(self.execute_sql(sql_fragment, *args, **kwargs))\n  File \"/usr/local/lib/python3.10/site-packages/dlt/destinations/impl/bigquery/sql_client.py\", line 196, in execute_sql\n    with self.execute_query(sql, *args, **kwargs) as curr:\n  File \"/usr/local/lib/python3.10/contextlib.py\", line 135, in __enter__\n    return next(self.gen)\n  File \"/usr/local/lib/python3.10/site-packages/dlt/destinations/sql_client.py\", line 245, in _wrap_gen\n    raise self._make_database_exception(ex)\ndlt.destinations.exceptions.DatabaseTransientException: 400 Already Exists: Table leafy-valor-420311:nba_api._dlt_version at [9:1]\n\nLocation: US\nJob ID: 3c3e8a51-33cf-4054-aafa-1837d9dc82f4\n\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/mage_ai/shared/retry.py\", line 38, in retry_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/executors/block_executor.py\", line 587, in __execute_with_retry\n    return self._execute(\n  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/executors/block_executor.py\", line 1075, in _execute\n    result = self.block.execute_sync(\n  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py\", line 1312, in execute_sync\n    raise err\n  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py\", line 1221, in execute_sync\n    output = self.execute_block(\n  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py\", line 1527, in execute_block\n    outputs = self._execute_block(\n  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py\", line 1683, in _execute_block\n    outputs = self.execute_block_function(\n  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py\", line 1722, in execute_block_function\n    output = block_function_updated(*input_vars, **global_vars)\n  File \"<string>\", line 26, in load_data\n  File \"/usr/local/lib/python3.10/site-packages/dlt/pipeline/pipeline.py\", line 193, in _wrap\n    step_info = f(self, *args, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/dlt/pipeline/pipeline.py\", line 238, in _wrap\n    return f(self, *args, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/dlt/pipeline/pipeline.py\", line 629, in run\n    return self.load(destination, dataset_name, credentials=credentials)\n  File \"/usr/local/lib/python3.10/site-packages/dlt/pipeline/pipeline.py\", line 193, in _wrap\n    step_info = f(self, *args, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/dlt/pipeline/pipeline.py\", line 164, in _wrap\n    rv = f(self, *args, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/dlt/pipeline/pipeline.py\", line 151, in _wrap\n    return f(self, *args, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/dlt/pipeline/pipeline.py\", line 238, in _wrap\n    return f(self, *args, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/dlt/pipeline/pipeline.py\", line 509, in load\n    raise PipelineStepFailed(\ndlt.pipeline.exceptions.PipelineStepFailed: Pipeline execution failed at stage load when processing package 1713112430.2459638 with exception:\n\n<class 'dlt.destinations.exceptions.DatabaseTransientException'>\n400 Already Exists: Table leafy-valor-420311:nba_api._dlt_version at [9:1]\n\nLocation: US\nJob ID: 3c3e8a51-33cf-4054-aafa-1837d9dc82f4\n\n"], "error_stack": [["  File \"/usr/local/bin/mage\", line 8, in <module>\n    sys.exit(app())\n", "  File \"/usr/local/lib/python3.10/site-packages/typer/main.py\", line 311, in __call__\n    return get_command(self)(*args, **kwargs)\n", "  File \"/usr/local/lib/python3.10/site-packages/click/core.py\", line 1130, in __call__\n    return self.main(*args, **kwargs)\n", "  File \"/usr/local/lib/python3.10/site-packages/typer/core.py\", line 778, in main\n    return _main(\n", "  File \"/usr/local/lib/python3.10/site-packages/typer/core.py\", line 216, in _main\n    rv = self.invoke(ctx)\n", "  File \"/usr/local/lib/python3.10/site-packages/click/core.py\", line 1657, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n", "  File \"/usr/local/lib/python3.10/site-packages/click/core.py\", line 1404, in invoke\n    return ctx.invoke(self.callback, **ctx.params)\n", "  File \"/usr/local/lib/python3.10/site-packages/click/core.py\", line 760, in invoke\n    return __callback(*args, **kwargs)\n", "  File \"/usr/local/lib/python3.10/site-packages/typer/main.py\", line 683, in wrapper\n    return callback(**use_params)  # type: ignore\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/cli/main.py\", line 163, in start\n    start_server(\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/server/server.py\", line 659, in start_server\n    scheduler_manager.start_scheduler()\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/server/scheduler_manager.py\", line 87, in start_scheduler\n    proc.start()\n", "  File \"/usr/local/lib/python3.10/multiprocessing/process.py\", line 121, in start\n    self._popen = self._Popen(self)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/context.py\", line 224, in _Popen\n    return _default_context.get_context().Process._Popen(process_obj)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/context.py\", line 281, in _Popen\n    return Popen(process_obj)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/popen_fork.py\", line 19, in __init__\n    self._launch(process_obj)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/popen_fork.py\", line 71, in _launch\n    code = process_obj._bootstrap(parent_sentinel=child_r)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n    self.run()\n", "  File \"/usr/local/lib/python3.10/multiprocessing/process.py\", line 108, in run\n    self._target(*self._args, **self._kwargs)\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/db/process.py\", line 15, in start_session_and_run\n    results = target(*args)\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/server/scheduler_manager.py\", line 50, in run_scheduler\n    LoopTimeTrigger().start()\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/triggers/loop_time_trigger.py\", line 14, in start\n    self.run()\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/triggers/time_trigger.py\", line 11, in run\n    schedule_all()\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/pipeline_scheduler_original.py\", line 1552, in schedule_all\n    PipelineScheduler(r).start()\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/db/__init__.py\", line 149, in func_with_rollback\n    return func(*args, **kwargs)\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/pipeline_scheduler_original.py\", line 182, in start\n    self.schedule()\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/db/__init__.py\", line 149, in func_with_rollback\n    return func(*args, **kwargs)\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/pipeline_scheduler_original.py\", line 319, in schedule\n    self.__schedule_blocks(block_runs)\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/pipeline_scheduler_original.py\", line 581, in __schedule_blocks\n    job_manager.add_job(\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/job_manager.py\", line 27, in add_job\n    self.queue.enqueue(job_id, target, *args, **kwargs)\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/queue/process_queue.py\", line 107, in enqueue\n    self.start_worker_pool()\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/queue/process_queue.py\", line 173, in start_worker_pool\n    self.worker_pool_proc.start()\n", "  File \"/usr/local/lib/python3.10/multiprocessing/process.py\", line 121, in start\n    self._popen = self._Popen(self)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/context.py\", line 224, in _Popen\n    return _default_context.get_context().Process._Popen(process_obj)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/context.py\", line 281, in _Popen\n    return Popen(process_obj)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/popen_fork.py\", line 19, in __init__\n    self._launch(process_obj)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/popen_fork.py\", line 71, in _launch\n    code = process_obj._bootstrap(parent_sentinel=child_r)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n    self.run()\n", "  File \"/usr/local/lib/python3.10/multiprocessing/process.py\", line 108, in run\n    self._target(*self._args, **self._kwargs)\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/queue/process_queue.py\", line 275, in poll_job_and_execute\n    worker.start()\n", "  File \"/usr/local/lib/python3.10/multiprocessing/process.py\", line 121, in start\n    self._popen = self._Popen(self)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/context.py\", line 224, in _Popen\n    return _default_context.get_context().Process._Popen(process_obj)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/context.py\", line 281, in _Popen\n    return Popen(process_obj)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/popen_fork.py\", line 19, in __init__\n    self._launch(process_obj)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/popen_fork.py\", line 71, in _launch\n    code = process_obj._bootstrap(parent_sentinel=child_r)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n    self.run()\n", "  File \"/usr/local/lib/python3.10/site-packages/newrelic/api/background_task.py\", line 117, in wrapper\n    return wrapped(*args, **kwargs)\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/queue/process_queue.py\", line 240, in run\n    start_session_and_run(args[1], *args[2], **args[3])\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/db/process.py\", line 15, in start_session_and_run\n    results = target(*args)\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/pipeline_scheduler_original.py\", line 1105, in run_block\n    return ExecutorFactory.get_block_executor(\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/executors/block_executor.py\", line 612, in execute\n    result = __execute_with_retry()\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/shared/retry.py\", line 46, in retry_func\n    logger.warning(\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/logging/logger.py\", line 39, in warning\n    self.__send_message('warning', message, **kwargs)\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/logging/logger.py\", line 59, in __send_message\n    data['error_stack'] = traceback.format_stack(),\n"]], "error_stacktrace": ["Pipeline execution failed at stage load when processing package 1713112430.2459638 with exception:\n\n<class 'dlt.destinations.exceptions.DatabaseTransientException'>\n400 Already Exists: Table leafy-valor-420311:nba_api._dlt_version at [9:1]\n\nLocation: US\nJob ID: 3c3e8a51-33cf-4054-aafa-1837d9dc82f4\n"]}
2024-04-14T16:33:54 {"block_run_id": 9, "block_uuid": "load_daily_schedule", "pipeline_run_id": 4, "pipeline_schedule_id": 4, "pipeline_uuid": "seed_bq", "hostname": "78c121f5c730", "block_type": "data_loader", "level": "EXCEPTION", "message": "Failed to execute block load_daily_schedule", "timestamp": 1713112434.466746, "uuid": "52b3f9329e2d4d168f6f27b77e7b0d70", "error": ["Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/google/cloud/bigquery/dbapi/cursor.py\", line 213, in _execute\n    self._query_job.result()\n  File \"/usr/local/lib/python3.10/site-packages/google/cloud/bigquery/job/query.py\", line 1595, in result\n    do_get_result()\n  File \"/usr/local/lib/python3.10/site-packages/google/api_core/retry.py\", line 372, in retry_wrapped_func\n    return retry_target(\n  File \"/usr/local/lib/python3.10/site-packages/google/api_core/retry.py\", line 207, in retry_target\n    result = target()\n  File \"/usr/local/lib/python3.10/site-packages/google/cloud/bigquery/job/query.py\", line 1584, in do_get_result\n    super(QueryJob, self).result(retry=retry, timeout=timeout)\n  File \"/usr/local/lib/python3.10/site-packages/google/cloud/bigquery/job/base.py\", line 952, in result\n    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/google/api_core/future/polling.py\", line 261, in result\n    raise self._exception\ngoogle.api_core.exceptions.BadRequest: 400 Already Exists: Table leafy-valor-420311:nba_api._dlt_version at [9:1]\n\nLocation: US\nJob ID: 3c3e8a51-33cf-4054-aafa-1837d9dc82f4\n\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/dlt/destinations/sql_client.py\", line 243, in _wrap_gen\n    return (yield from f(self, *args, **kwargs))\n  File \"/usr/local/lib/python3.10/site-packages/dlt/destinations/impl/bigquery/sql_client.py\", line 215, in execute_query\n    curr.execute(query, db_args, job_config=self._session_query or self._default_query)\n  File \"/usr/local/lib/python3.10/site-packages/google/cloud/bigquery/dbapi/_helpers.py\", line 494, in with_closed_check\n    return method(self, *args, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/google/cloud/bigquery/dbapi/cursor.py\", line 176, in execute\n    self._execute(\n  File \"/usr/local/lib/python3.10/site-packages/google/cloud/bigquery/dbapi/cursor.py\", line 215, in _execute\n    raise exceptions.DatabaseError(exc)\ngoogle.cloud.bigquery.dbapi.exceptions.DatabaseError: 400 Already Exists: Table leafy-valor-420311:nba_api._dlt_version at [9:1]\n\nLocation: US\nJob ID: 3c3e8a51-33cf-4054-aafa-1837d9dc82f4\n\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/dlt/pipeline/pipeline.py\", line 503, in load\n    runner.run_pool(load_step.config, load_step)\n  File \"/usr/local/lib/python3.10/site-packages/dlt/common/runners/pool_runner.py\", line 88, in run_pool\n    while _run_func():\n  File \"/usr/local/lib/python3.10/site-packages/dlt/common/runners/pool_runner.py\", line 81, in _run_func\n    run_metrics = run_f.run(cast(TExecutor, pool))\n  File \"/usr/local/lib/python3.10/site-packages/dlt/load/load.py\", line 564, in run\n    self.load_single_package(load_id, schema)\n  File \"/usr/local/lib/python3.10/site-packages/dlt/load/load.py\", line 448, in load_single_package\n    applied_update = self._init_client(\n  File \"/usr/local/lib/python3.10/site-packages/dlt/load/load.py\", line 423, in _init_client\n    applied_update = self._init_dataset_and_update_schema(\n  File \"/usr/local/lib/python3.10/site-packages/dlt/load/load.py\", line 398, in _init_dataset_and_update_schema\n    applied_update = job_client.update_stored_schema(\n  File \"/usr/local/lib/python3.10/site-packages/dlt/destinations/job_client_impl.py\", line 200, in update_stored_schema\n    applied_update = self._execute_schema_update_sql(only_tables)\n  File \"/usr/local/lib/python3.10/site-packages/dlt/destinations/job_client_impl.py\", line 399, in _execute_schema_update_sql\n    self.sql_client.execute_many(sql_scripts)\n  File \"/usr/local/lib/python3.10/site-packages/dlt/destinations/sql_client.py\", line 133, in execute_many\n    ret.append(self.execute_sql(sql_fragment, *args, **kwargs))\n  File \"/usr/local/lib/python3.10/site-packages/dlt/destinations/impl/bigquery/sql_client.py\", line 196, in execute_sql\n    with self.execute_query(sql, *args, **kwargs) as curr:\n  File \"/usr/local/lib/python3.10/contextlib.py\", line 135, in __enter__\n    return next(self.gen)\n  File \"/usr/local/lib/python3.10/site-packages/dlt/destinations/sql_client.py\", line 245, in _wrap_gen\n    raise self._make_database_exception(ex)\ndlt.destinations.exceptions.DatabaseTransientException: 400 Already Exists: Table leafy-valor-420311:nba_api._dlt_version at [9:1]\n\nLocation: US\nJob ID: 3c3e8a51-33cf-4054-aafa-1837d9dc82f4\n\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/executors/block_executor.py\", line 612, in execute\n    result = __execute_with_retry()\n  File \"/usr/local/lib/python3.10/site-packages/mage_ai/shared/retry.py\", line 54, in retry_func\n    raise e\n  File \"/usr/local/lib/python3.10/site-packages/mage_ai/shared/retry.py\", line 38, in retry_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/executors/block_executor.py\", line 587, in __execute_with_retry\n    return self._execute(\n  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/executors/block_executor.py\", line 1075, in _execute\n    result = self.block.execute_sync(\n  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py\", line 1312, in execute_sync\n    raise err\n  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py\", line 1221, in execute_sync\n    output = self.execute_block(\n  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py\", line 1527, in execute_block\n    outputs = self._execute_block(\n  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py\", line 1683, in _execute_block\n    outputs = self.execute_block_function(\n  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py\", line 1722, in execute_block_function\n    output = block_function_updated(*input_vars, **global_vars)\n  File \"<string>\", line 26, in load_data\n  File \"/usr/local/lib/python3.10/site-packages/dlt/pipeline/pipeline.py\", line 193, in _wrap\n    step_info = f(self, *args, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/dlt/pipeline/pipeline.py\", line 238, in _wrap\n    return f(self, *args, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/dlt/pipeline/pipeline.py\", line 629, in run\n    return self.load(destination, dataset_name, credentials=credentials)\n  File \"/usr/local/lib/python3.10/site-packages/dlt/pipeline/pipeline.py\", line 193, in _wrap\n    step_info = f(self, *args, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/dlt/pipeline/pipeline.py\", line 164, in _wrap\n    rv = f(self, *args, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/dlt/pipeline/pipeline.py\", line 151, in _wrap\n    return f(self, *args, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/dlt/pipeline/pipeline.py\", line 238, in _wrap\n    return f(self, *args, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/dlt/pipeline/pipeline.py\", line 509, in load\n    raise PipelineStepFailed(\ndlt.pipeline.exceptions.PipelineStepFailed: Pipeline execution failed at stage load when processing package 1713112430.2459638 with exception:\n\n<class 'dlt.destinations.exceptions.DatabaseTransientException'>\n400 Already Exists: Table leafy-valor-420311:nba_api._dlt_version at [9:1]\n\nLocation: US\nJob ID: 3c3e8a51-33cf-4054-aafa-1837d9dc82f4\n\n"], "error_stack": [["  File \"/usr/local/bin/mage\", line 8, in <module>\n    sys.exit(app())\n", "  File \"/usr/local/lib/python3.10/site-packages/typer/main.py\", line 311, in __call__\n    return get_command(self)(*args, **kwargs)\n", "  File \"/usr/local/lib/python3.10/site-packages/click/core.py\", line 1130, in __call__\n    return self.main(*args, **kwargs)\n", "  File \"/usr/local/lib/python3.10/site-packages/typer/core.py\", line 778, in main\n    return _main(\n", "  File \"/usr/local/lib/python3.10/site-packages/typer/core.py\", line 216, in _main\n    rv = self.invoke(ctx)\n", "  File \"/usr/local/lib/python3.10/site-packages/click/core.py\", line 1657, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n", "  File \"/usr/local/lib/python3.10/site-packages/click/core.py\", line 1404, in invoke\n    return ctx.invoke(self.callback, **ctx.params)\n", "  File \"/usr/local/lib/python3.10/site-packages/click/core.py\", line 760, in invoke\n    return __callback(*args, **kwargs)\n", "  File \"/usr/local/lib/python3.10/site-packages/typer/main.py\", line 683, in wrapper\n    return callback(**use_params)  # type: ignore\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/cli/main.py\", line 163, in start\n    start_server(\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/server/server.py\", line 659, in start_server\n    scheduler_manager.start_scheduler()\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/server/scheduler_manager.py\", line 87, in start_scheduler\n    proc.start()\n", "  File \"/usr/local/lib/python3.10/multiprocessing/process.py\", line 121, in start\n    self._popen = self._Popen(self)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/context.py\", line 224, in _Popen\n    return _default_context.get_context().Process._Popen(process_obj)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/context.py\", line 281, in _Popen\n    return Popen(process_obj)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/popen_fork.py\", line 19, in __init__\n    self._launch(process_obj)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/popen_fork.py\", line 71, in _launch\n    code = process_obj._bootstrap(parent_sentinel=child_r)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n    self.run()\n", "  File \"/usr/local/lib/python3.10/multiprocessing/process.py\", line 108, in run\n    self._target(*self._args, **self._kwargs)\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/db/process.py\", line 15, in start_session_and_run\n    results = target(*args)\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/server/scheduler_manager.py\", line 50, in run_scheduler\n    LoopTimeTrigger().start()\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/triggers/loop_time_trigger.py\", line 14, in start\n    self.run()\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/triggers/time_trigger.py\", line 11, in run\n    schedule_all()\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/pipeline_scheduler_original.py\", line 1552, in schedule_all\n    PipelineScheduler(r).start()\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/db/__init__.py\", line 149, in func_with_rollback\n    return func(*args, **kwargs)\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/pipeline_scheduler_original.py\", line 182, in start\n    self.schedule()\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/db/__init__.py\", line 149, in func_with_rollback\n    return func(*args, **kwargs)\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/pipeline_scheduler_original.py\", line 319, in schedule\n    self.__schedule_blocks(block_runs)\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/pipeline_scheduler_original.py\", line 581, in __schedule_blocks\n    job_manager.add_job(\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/job_manager.py\", line 27, in add_job\n    self.queue.enqueue(job_id, target, *args, **kwargs)\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/queue/process_queue.py\", line 107, in enqueue\n    self.start_worker_pool()\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/queue/process_queue.py\", line 173, in start_worker_pool\n    self.worker_pool_proc.start()\n", "  File \"/usr/local/lib/python3.10/multiprocessing/process.py\", line 121, in start\n    self._popen = self._Popen(self)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/context.py\", line 224, in _Popen\n    return _default_context.get_context().Process._Popen(process_obj)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/context.py\", line 281, in _Popen\n    return Popen(process_obj)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/popen_fork.py\", line 19, in __init__\n    self._launch(process_obj)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/popen_fork.py\", line 71, in _launch\n    code = process_obj._bootstrap(parent_sentinel=child_r)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n    self.run()\n", "  File \"/usr/local/lib/python3.10/multiprocessing/process.py\", line 108, in run\n    self._target(*self._args, **self._kwargs)\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/queue/process_queue.py\", line 275, in poll_job_and_execute\n    worker.start()\n", "  File \"/usr/local/lib/python3.10/multiprocessing/process.py\", line 121, in start\n    self._popen = self._Popen(self)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/context.py\", line 224, in _Popen\n    return _default_context.get_context().Process._Popen(process_obj)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/context.py\", line 281, in _Popen\n    return Popen(process_obj)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/popen_fork.py\", line 19, in __init__\n    self._launch(process_obj)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/popen_fork.py\", line 71, in _launch\n    code = process_obj._bootstrap(parent_sentinel=child_r)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n    self.run()\n", "  File \"/usr/local/lib/python3.10/site-packages/newrelic/api/background_task.py\", line 117, in wrapper\n    return wrapped(*args, **kwargs)\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/queue/process_queue.py\", line 240, in run\n    start_session_and_run(args[1], *args[2], **args[3])\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/db/process.py\", line 15, in start_session_and_run\n    results = target(*args)\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/pipeline_scheduler_original.py\", line 1105, in run_block\n    return ExecutorFactory.get_block_executor(\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/executors/block_executor.py\", line 614, in execute\n    self.logger.exception(\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/logging/logger.py\", line 30, in exception\n    self.__send_message('exception', message, **kwargs)\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/logging/logger.py\", line 59, in __send_message\n    data['error_stack'] = traceback.format_stack(),\n"]], "error_stacktrace": ["Pipeline execution failed at stage load when processing package 1713112430.2459638 with exception:\n\n<class 'dlt.destinations.exceptions.DatabaseTransientException'>\n400 Already Exists: Table leafy-valor-420311:nba_api._dlt_version at [9:1]\n\nLocation: US\nJob ID: 3c3e8a51-33cf-4054-aafa-1837d9dc82f4\n"]}
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/google/cloud/bigquery/dbapi/cursor.py", line 213, in _execute
    self._query_job.result()
  File "/usr/local/lib/python3.10/site-packages/google/cloud/bigquery/job/query.py", line 1595, in result
    do_get_result()
  File "/usr/local/lib/python3.10/site-packages/google/api_core/retry.py", line 372, in retry_wrapped_func
    return retry_target(
  File "/usr/local/lib/python3.10/site-packages/google/api_core/retry.py", line 207, in retry_target
    result = target()
  File "/usr/local/lib/python3.10/site-packages/google/cloud/bigquery/job/query.py", line 1584, in do_get_result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.10/site-packages/google/cloud/bigquery/job/base.py", line 952, in result
    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/google/api_core/future/polling.py", line 261, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Already Exists: Table leafy-valor-420311:nba_api._dlt_version at [9:1]

Location: US
Job ID: 3c3e8a51-33cf-4054-aafa-1837d9dc82f4


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/dlt/destinations/sql_client.py", line 243, in _wrap_gen
    return (yield from f(self, *args, **kwargs))
  File "/usr/local/lib/python3.10/site-packages/dlt/destinations/impl/bigquery/sql_client.py", line 215, in execute_query
    curr.execute(query, db_args, job_config=self._session_query or self._default_query)
  File "/usr/local/lib/python3.10/site-packages/google/cloud/bigquery/dbapi/_helpers.py", line 494, in with_closed_check
    return method(self, *args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/google/cloud/bigquery/dbapi/cursor.py", line 176, in execute
    self._execute(
  File "/usr/local/lib/python3.10/site-packages/google/cloud/bigquery/dbapi/cursor.py", line 215, in _execute
    raise exceptions.DatabaseError(exc)
google.cloud.bigquery.dbapi.exceptions.DatabaseError: 400 Already Exists: Table leafy-valor-420311:nba_api._dlt_version at [9:1]

Location: US
Job ID: 3c3e8a51-33cf-4054-aafa-1837d9dc82f4


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/dlt/pipeline/pipeline.py", line 503, in load
    runner.run_pool(load_step.config, load_step)
  File "/usr/local/lib/python3.10/site-packages/dlt/common/runners/pool_runner.py", line 88, in run_pool
    while _run_func():
  File "/usr/local/lib/python3.10/site-packages/dlt/common/runners/pool_runner.py", line 81, in _run_func
    run_metrics = run_f.run(cast(TExecutor, pool))
  File "/usr/local/lib/python3.10/site-packages/dlt/load/load.py", line 564, in run
    self.load_single_package(load_id, schema)
  File "/usr/local/lib/python3.10/site-packages/dlt/load/load.py", line 448, in load_single_package
    applied_update = self._init_client(
  File "/usr/local/lib/python3.10/site-packages/dlt/load/load.py", line 423, in _init_client
    applied_update = self._init_dataset_and_update_schema(
  File "/usr/local/lib/python3.10/site-packages/dlt/load/load.py", line 398, in _init_dataset_and_update_schema
    applied_update = job_client.update_stored_schema(
  File "/usr/local/lib/python3.10/site-packages/dlt/destinations/job_client_impl.py", line 200, in update_stored_schema
    applied_update = self._execute_schema_update_sql(only_tables)
  File "/usr/local/lib/python3.10/site-packages/dlt/destinations/job_client_impl.py", line 399, in _execute_schema_update_sql
    self.sql_client.execute_many(sql_scripts)
  File "/usr/local/lib/python3.10/site-packages/dlt/destinations/sql_client.py", line 133, in execute_many
    ret.append(self.execute_sql(sql_fragment, *args, **kwargs))
  File "/usr/local/lib/python3.10/site-packages/dlt/destinations/impl/bigquery/sql_client.py", line 196, in execute_sql
    with self.execute_query(sql, *args, **kwargs) as curr:
  File "/usr/local/lib/python3.10/contextlib.py", line 135, in __enter__
    return next(self.gen)
  File "/usr/local/lib/python3.10/site-packages/dlt/destinations/sql_client.py", line 245, in _wrap_gen
    raise self._make_database_exception(ex)
dlt.destinations.exceptions.DatabaseTransientException: 400 Already Exists: Table leafy-valor-420311:nba_api._dlt_version at [9:1]

Location: US
Job ID: 3c3e8a51-33cf-4054-aafa-1837d9dc82f4


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/executors/block_executor.py", line 612, in execute
    result = __execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/mage_ai/shared/retry.py", line 54, in retry_func
    raise e
  File "/usr/local/lib/python3.10/site-packages/mage_ai/shared/retry.py", line 38, in retry_func
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/executors/block_executor.py", line 587, in __execute_with_retry
    return self._execute(
  File "/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/executors/block_executor.py", line 1075, in _execute
    result = self.block.execute_sync(
  File "/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py", line 1312, in execute_sync
    raise err
  File "/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py", line 1221, in execute_sync
    output = self.execute_block(
  File "/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py", line 1527, in execute_block
    outputs = self._execute_block(
  File "/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py", line 1683, in _execute_block
    outputs = self.execute_block_function(
  File "/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py", line 1722, in execute_block_function
    output = block_function_updated(*input_vars, **global_vars)
  File "<string>", line 26, in load_data
  File "/usr/local/lib/python3.10/site-packages/dlt/pipeline/pipeline.py", line 193, in _wrap
    step_info = f(self, *args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/dlt/pipeline/pipeline.py", line 238, in _wrap
    return f(self, *args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/dlt/pipeline/pipeline.py", line 629, in run
    return self.load(destination, dataset_name, credentials=credentials)
  File "/usr/local/lib/python3.10/site-packages/dlt/pipeline/pipeline.py", line 193, in _wrap
    step_info = f(self, *args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/dlt/pipeline/pipeline.py", line 164, in _wrap
    rv = f(self, *args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/dlt/pipeline/pipeline.py", line 151, in _wrap
    return f(self, *args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/dlt/pipeline/pipeline.py", line 238, in _wrap
    return f(self, *args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/dlt/pipeline/pipeline.py", line 509, in load
    raise PipelineStepFailed(
dlt.pipeline.exceptions.PipelineStepFailed: Pipeline execution failed at stage load when processing package 1713112430.2459638 with exception:

<class 'dlt.destinations.exceptions.DatabaseTransientException'>
400 Already Exists: Table leafy-valor-420311:nba_api._dlt_version at [9:1]

Location: US
Job ID: 3c3e8a51-33cf-4054-aafa-1837d9dc82f4

