{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "571e349a-e185-466d-87b2-fa17c83f6de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import IntegerType, StringType, LongType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c62dba0-37ff-4172-b53c-810493a4047e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdae713-44db-425d-9a55-101e7e4cde0a",
   "metadata": {},
   "source": [
    "## Question 1: Install PySpark \n",
    "### What is the installed Spark version?\n",
    "The version of Spark installed on this machine is 3.5.0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69f7c80d-6826-4fc6-abae-9c1c1425e70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PySpark version: 3.5.0\n"
     ]
    }
   ],
   "source": [
    "# Version check \n",
    "print(f\"PySpark version: {spark.version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35326bea-f061-4d0e-9092-8245b33d193d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV file path \n",
    "csv_path = '../data/source/fhv_tripdata_2019-10.csv.gz'\n",
    "\n",
    "# Read CSV\n",
    "csv_df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .csv(csv_path)\n",
    "\n",
    "# Repartition \n",
    "csv_df = csv_df.repartition(6)\n",
    "\n",
    "# Save to disk \n",
    "csv_df.write \\\n",
    "    .format(\"parquet\") \\\n",
    "    .mode(\"Overwrite\") \\\n",
    "    .save('../data/output/csv_input/2019/10')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74b9017-c487-4280-9b7b-d187406eed69",
   "metadata": {},
   "source": [
    "## Question 2: Repartition \n",
    "### Repartition the Spark Dataframe to 6 partitions and save it to parquet. \n",
    "After repartitioning the Dataframe, the resulting parquet files were roughly 6MB each. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e4b2906-ea20-4003-94d0-7b6fb079f90d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in FHV 2019 data as parquet\n",
    "file_path = '../data/source/fhv_tripdata_2019-10.parquet'\n",
    "df_fhv = spark.read \\\n",
    "    .parquet(file_path)\n",
    "\n",
    "# Repartition and save \n",
    "df_fhv = df_fhv.repartition(6)\n",
    "\n",
    "# Confirm number of parititions \n",
    "df_fhv.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c3756c4-ed18-4a92-a0f2-0a5fb4c0cd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write partitioned dataframe to disk \n",
    "df_fhv.write \\\n",
    "    .format(\"parquet\") \\\n",
    "    .mode(\"Overwrite\") \\\n",
    "    .save('../data/output/2019/10/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e994442b-e735-4475-87eb-e8e667991b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in taxi data\n",
    "taxi_path = '../data/source/taxi_zone_lookup.csv'\n",
    "\n",
    "df_taxi = spark.read \\\n",
    "            .format('csv') \\\n",
    "            .option('header', 'true') \\\n",
    "            .load(taxi_path)\n",
    "\n",
    "# Create temporary view for later \n",
    "df_taxi.createOrReplaceTempView(\"taxi_lookup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4df51538-6c65-4660-9ac2-2b0fd7d9ec36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create additional columns in FHV dataframe to answer remaining homework questions \n",
    "\n",
    "# Create a pickup date column\n",
    "df_fhv = df_fhv.withColumn(\"pickup_date\", F.to_date(F.col('pickup_datetime')))\n",
    "\n",
    "# Convert pickup_datetime to timestamp and then seconds to perform date difference in hours\n",
    "df_fhv = df_fhv.withColumn(\"pickup_datetime_seconds\", F.to_timestamp(F.col(\"pickup_datetime\")).cast(LongType()))\n",
    "df_fhv = df_fhv.withColumn(\"dropoff_datetime_seconds\", F.to_timestamp(F.col(\"dropoff_datetime\")).cast(LongType()))\n",
    "df_fhv = df_fhv.withColumn(\"trip_duration_hours\", (F.col(\"dropoff_datetime_seconds\") - F.col(\"pickup_datetime_seconds\"))/3600)\n",
    "\n",
    "# Create view for FHV data\n",
    "df_fhv.createOrReplaceTempView('fhv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e464a7-d09c-44dc-a37f-b95ad6ca471e",
   "metadata": {},
   "source": [
    "## Question 3: Count Records\n",
    "### How many trip were there on the 15th of October?\n",
    "There were 62629 trips on October 15, 2019. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b660c4c8-4dab-4a08-a96d-9db37099f487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|num_trips_oct_15|\n",
      "+----------------+\n",
      "|           62629|\n",
      "+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count number of records for trips that started on October 15\n",
    "spark.sql(\"\"\"\n",
    "SELECT \n",
    "    COUNT(*) AS num_trips_oct_15\n",
    "FROM fhv\n",
    "WHERE day(pickup_datetime) = 15 AND month(pickup_datetime) = 10 AND year(pickup_datetime) = 2019\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c5fd7c-19da-42f6-83fb-b01e112a46d0",
   "metadata": {},
   "source": [
    "## Question 4: Longest trip for each day\n",
    "### What is the length of the longest trip in the dataset in hours?\n",
    "\n",
    "The longest trip in the dataset is 632,152.50 hours long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a75dc6c3-4b45-44bd-b778-6c1a17d92cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------------------+\n",
      "|pickup_date|daily_max_trip_duration_hours|\n",
      "+-----------+-----------------------------+\n",
      "| 2019-10-28|                     631152.5|\n",
      "| 2019-10-11|                     631152.5|\n",
      "| 2019-10-31|            87672.44083333333|\n",
      "| 2019-10-01|            70128.02805555555|\n",
      "| 2019-10-17|                       8794.0|\n",
      "| 2019-10-26|            8784.166666666666|\n",
      "| 2019-10-30|           1465.5344444444445|\n",
      "| 2019-10-25|           1057.8266666666666|\n",
      "| 2019-10-02|            770.2313888888889|\n",
      "| 2019-10-23|            746.6166666666667|\n",
      "| 2019-10-03|                     746.3825|\n",
      "| 2019-10-04|            745.6166666666667|\n",
      "| 2019-10-07|            745.1666666666666|\n",
      "| 2019-10-05|            698.1808333333333|\n",
      "| 2019-10-06|            675.0077777777777|\n",
      "| 2019-10-08|            626.0822222222222|\n",
      "| 2019-10-16|            605.0666666666667|\n",
      "| 2019-10-09|            602.3102777777777|\n",
      "| 2019-10-10|            578.3888888888889|\n",
      "| 2019-10-12|                     529.9125|\n",
      "+-----------+-----------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Longest trip in hours\n",
    "spark.sql(\"\"\"\n",
    "SELECT \n",
    "    pickup_date,\n",
    "    MAX(trip_duration_hours) AS daily_max_trip_duration_hours\n",
    "FROM fhv\n",
    "GROUP BY pickup_date\n",
    "ORDER BY daily_max_trip_duration_hours DESC\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdeccb9-354c-46f6-aaf8-42552653fa34",
   "metadata": {},
   "source": [
    "## Question 5: User Interface\n",
    "### What local port does Spark's User Interface run on?\n",
    "Spark's User Interface runs on local port 4040 by default. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bf0c2d-0785-47a4-b03d-a59bafe1852c",
   "metadata": {},
   "source": [
    "## Question 6: Least frequent pickup location zone\n",
    "### What is the name of the least frequent pickup zone?\n",
    "Jamaica Bay is the name of the pickup zone with the least amount of trips. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "270a8a2b-50d7-4a0e-909e-23802aaa056e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+\n",
      "|                Zone|num_trips|\n",
      "+--------------------+---------+\n",
      "|         Jamaica Bay|        1|\n",
      "|Governor's Island...|        2|\n",
      "| Green-Wood Cemetery|        5|\n",
      "|       Broad Channel|        8|\n",
      "|     Highbridge Park|       14|\n",
      "|        Battery Park|       15|\n",
      "|Saint Michaels Ce...|       23|\n",
      "|Breezy Point/Fort...|       25|\n",
      "|Marine Park/Floyd...|       26|\n",
      "|        Astoria Park|       29|\n",
      "|    Inwood Hill Park|       39|\n",
      "|       Willets Point|       47|\n",
      "|Forest Park/Highl...|       53|\n",
      "|  Brooklyn Navy Yard|       57|\n",
      "|        Crotona Park|       62|\n",
      "|        Country Club|       77|\n",
      "|     Freshkills Park|       89|\n",
      "|       Prospect Park|       98|\n",
      "|     Columbia Street|      105|\n",
      "|  South Williamsburg|      110|\n",
      "+--------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find least frequent pickup location zone \n",
    "spark.sql(\"\"\"\n",
    "SELECT \n",
    "    l.Zone,\n",
    "    COUNT(*) AS num_trips\n",
    "FROM fhv as f\n",
    "LEFT JOIN taxi_lookup AS l \n",
    "    ON f.PULocationID = l.LocationID\n",
    "GROUP BY l.Zone\n",
    "ORDER BY num_trips ASC\n",
    "\"\"\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
